{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6460a4-fb68-4bf6-b060-ca300e192dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 加载预训练的BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_keywords():\n",
    "    # 打开文件对话框，让用户选择要上传的文件\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\n",
    "    \n",
    "    # 读取用户选择的文件内容\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # 将文本数据转换为适合BERT模型输入的格式\n",
    "    inputs = tokenizer(text, return_tensors='tf')\n",
    "\n",
    "    # 输入文本数据到BERT模型中，获取模型的输出\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 获取模型的序列输出\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    # 计算每个输入文本的文本向量，即将其序列输出中的每个词向量相加\n",
    "    text_vectors = tf.reduce_sum(last_hidden_state, axis=1)\n",
    "\n",
    "    # 计算文本向量之间的余弦相似度\n",
    "    text_vectors_transpose = tf.transpose(text_vectors)\n",
    "    similarities = tf.matmul(text_vectors, text_vectors_transpose) / (tf.norm(text_vectors, axis=1, keepdims=True) * tf.norm(text_vectors_transpose, axis=0, keepdims=True))\n",
    "\n",
    "    # 找到与其他文本最不相似的文本索引\n",
    "    least_similar_index = np.argmin(np.sum(similarities, axis=0))\n",
    "\n",
    "    # 提取关键词\n",
    "    keywords = tokenizer.convert_ids_to_tokens(inputs['input_ids'][least_similar_index].numpy())\n",
    "\n",
    "    # 将提取的关键词结果显示在文本框中\n",
    "    result_text.delete('1.0', tk.END)\n",
    "    result_text.insert(tk.END, f\"Keywords: {' '.join(keywords)}\")\n",
    "\n",
    "# 创建主窗口\n",
    "root = tk.Tk()\n",
    "root.title(\"关键词提取工具\")\n",
    "\n",
    "# 创建上传按钮\n",
    "upload_button = tk.Button(root, text=\"上传文件\", command=extract_keywords)\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "# 创建显示结果的文本框\n",
    "result_text = tk.Text(root, height=20, width=50)\n",
    "result_text.pack()\n",
    "\n",
    "# 运行主循环\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6a1c7a-7daa-48f1-bf38-e7ea61db4e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "# 加载预训练的BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_keywords():\n",
    "    # 打开文件对话框，让用户选择要上传的文件\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\n",
    "    \n",
    "    # 读取用户选择的文件内容\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # 将文本数据转换为适合BERT模型输入的格式\n",
    "    inputs = tokenizer(text, return_tensors='tf')\n",
    "\n",
    "    # 输入文本数据到BERT模型中，获取模型的输出\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 获取模型的序列输出\n",
    "    sequence_output = outputs.last_hidden_state\n",
    "\n",
    "    # 计算每个词语的范数作为重要性分数\n",
    "    word_scores = tf.norm(sequence_output, axis=-1)\n",
    "\n",
    "    # 获取每个词语的重要性分数\n",
    "    word_scores = word_scores.numpy()[0]\n",
    "\n",
    "    # 获取词语列表\n",
    "    word_list = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].numpy())\n",
    "\n",
    "    # 构建关键词-重要性分数字典\n",
    "    keyword_scores = {word: score for word, score in zip(word_list, word_scores)}\n",
    "\n",
    "    # 按照重要性分数降序排列关键词\n",
    "    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 将提取的关键词结果显示在文本框中\n",
    "    result_text.delete('1.0', tk.END)\n",
    "    for keyword, score in sorted_keywords:\n",
    "        result_text.insert(tk.END, f\"{keyword}: {score}\\n\")\n",
    "\n",
    "# 创建主窗口\n",
    "root = tk.Tk()\n",
    "root.title(\"关键词提取工具\")\n",
    "\n",
    "# 创建上传按钮\n",
    "upload_button = tk.Button(root, text=\"上传文件\", command=extract_keywords)\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "# 创建显示结果的文本框\n",
    "result_text = tk.Text(root, height=20, width=50)\n",
    "result_text.pack()\n",
    "\n",
    "# 运行主循环\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b9195-8cdd-4a24-b2ee-4fe3e4e920da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
